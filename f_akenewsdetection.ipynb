{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q3yyNA4x7u8A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# If you want to visualize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Read using file path\n",
        "file_path = '/content/archive (4).zip'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUde0xGP8tCD",
        "outputId": "ca8caa70-6c02-41d4-82c1-925dcb2f82d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head()) # View the first 5 rows\n",
        "print(df.info()) # View the data types, number of non-null values\n",
        "print(df.describe()) # View the statistical summary (for numerical columns only)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-tcIv5V9Mhy",
        "outputId": "14720f04-b02f-45f8-d9ad-27639c74b381"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text label\n",
            "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
            "1  U.S. conservative leader optimistic of common ...  Real\n",
            "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
            "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
            "4  Democrats say Trump agrees to work on immigrat...  Real\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9900 entries, 0 to 9899\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Text    9900 non-null   object\n",
            " 1   label   9900 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 154.8+ KB\n",
            "None\n",
            "                                                     Text label\n",
            "count                                                9900  9900\n",
            "unique                                               9865     2\n",
            "top     Highlights: The Trump presidency on April 13 a...  Fake\n",
            "freq                                                    8  5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvGeWbpq9VBG",
        "outputId": "a885f337-5b48-4d8c-a6fa-75bf3dee13d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text     0\n",
            "label    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "7RBDb_u4-R3c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- (A) Load the File ---\n",
        "# 'files.upload()' is used to load a local file into Colab,\n",
        "# but since you've already uploaded the file, we'll use its name directly.\n",
        "\n",
        "file_path = \"/content/archive (4).zip\"\n",
        "try:\n",
        "  df = pd.read_csv(file_path)\n",
        "  print(\"Dataset successfully loaded.\")\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: File not found at {file_path}. Please check the file name.\")\n",
        "# If the file does not load, stop before running further code.\n",
        "# You can use the following code for manual upload:\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# import io\n",
        "# df = pd.read_csv(io.BytesIO(uploaded['fake_and_real_news.csv']))\n",
        "\n",
        "# --- (B) Check the data ---\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nColumn information and Missing Values ​​check:\")\n",
        "df.info()\n",
        "\n",
        "# --- (C) Label Encoding (Target Column) ---\n",
        "# The machine learning model will need to convert the 'Fake' and 'Real' labels to 0 and 1.\n",
        "df['label'] = df['label'].map({'Fake': 0, 'Real': 1})\n",
        "\n",
        "print(\"\\nLabel Distribution (0=Fake, 1=Real):\")\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdICbp_p_a8_",
        "outputId": "7534fe78-70fd-45bb-c680-0a68ea7e53c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset successfully loaded.\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "                                                Text label\n",
            "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
            "1  U.S. conservative leader optimistic of common ...  Real\n",
            "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
            "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
            "4  Democrats say Trump agrees to work on immigrat...  Real\n",
            "\n",
            "Column information and Missing Values ​​check:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9900 entries, 0 to 9899\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Text    9900 non-null   object\n",
            " 1   label   9900 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 154.8+ KB\n",
            "\n",
            "Label Distribution (0=Fake, 1=Real):\n",
            "label\n",
            "0    5000\n",
            "1    4900\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Corrected Import ---\n",
        "import nltk\n",
        "\n",
        "# Download NLTK packages (Run this once)\n",
        "print(\"Downloading necessary NLTK components...\")\n",
        "nltk.download('stopwords')\n",
        "print(\"NLTK downloads complete.\")\n",
        "\n",
        "# You can now proceed to the Text Preprocessing code block."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfc1gqojAIs3",
        "outputId": "d125471e-f1f2-4ab0-e0b5-74d4b49a8279"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading necessary NLTK components...\n",
            "NLTK downloads complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# NLTK Setup\n",
        "porter = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Function to clean the text and perform stemming.\"\"\"\n",
        "    # Handle NaN values: If the input is not a string, convert it to an empty string\n",
        "    # to prevent further errors during regex/lower-casing.\n",
        "    if pd.isna(text):\n",
        "        text = \"\"\n",
        "\n",
        "    # 1. Remove non-alphabetic characters and numbers\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    # 2. Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # 3. Tokenize (split into words)\n",
        "    words = text.split()\n",
        "    # 4. Remove Stop Words and Stemming\n",
        "    words = [porter.stem(word) for word in words if word not in stop_words]\n",
        "    # 5. Join words back into a single string\n",
        "    return ' '.join(words)\n",
        "\n",
        "# --- (A) Apply Preprocessing ---\n",
        "print(\"\\nApplying text preprocessing...\")\n",
        "\n",
        "# --- THE FIX IS HERE: Changed 'text' to 'Text' ---\n",
        "df['clean_text'] = df['Text'].apply(preprocess_text)\n",
        "# --------------------------------------------------\n",
        "\n",
        "print(\"Preprocessing Complete.\")\n",
        "\n",
        "# --- (B) Separate Features (X) and Target (y) ---\n",
        "X = df['clean_text'] # The cleaned text\n",
        "y = df['label']      # The binary label\n",
        "\n",
        "# --- (C) Split Data into Train and Test Sets ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- (D) TF-IDF Vectorizer ---\n",
        "# Convert text documents to a matrix of TF-IDF features\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"\\nText Vectorization Complete.\")\n",
        "print(f\"Training Features shape: {X_train_tfidf.shape}\")\n",
        "print(f\"Testing Features shape: {X_test_tfidf.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCi_eBHTAXRL",
        "outputId": "e6c1df6a-3667-4adb-e06b-190a7ac2a08e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Applying text preprocessing...\n",
            "Preprocessing Complete.\n",
            "\n",
            "Text Vectorization Complete.\n",
            "Training Features shape: (7920, 5000)\n",
            "Testing Features shape: (1980, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- (A) Train the Model ---\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "print(\"\\nTraining the Logistic Regression Model...\")\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "print(\"Model Training Complete.\")\n",
        "\n",
        "# --- (B) Predict on the Test Set ---\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# --- (C) Evaluate the Model ---\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- Model Evaluation Results ---\")\n",
        "print(f\"Accuracy Score: {accuracy * 100:.2f}%\")\n",
        "\n",
        "print(\"\\nClassification Report (Detailed Metrics):\")\n",
        "# The report shows Precision, Recall, and F1-score for both Fake (0) and Real (1) classes.\n",
        "print(classification_report(y_test, y_pred, target_names=['Fake (0)', 'Real (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTJmdZalAtT-",
        "outputId": "148debda-c902-40d0-9845-a6bcca4b6051"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the Logistic Regression Model...\n",
            "Model Training Complete.\n",
            "\n",
            "--- Model Evaluation Results ---\n",
            "Accuracy Score: 98.94%\n",
            "\n",
            "Classification Report (Detailed Metrics):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Fake (0)       0.99      0.99      0.99      1000\n",
            "    Real (1)       0.99      0.99      0.99       980\n",
            "\n",
            "    accuracy                           0.99      1980\n",
            "   macro avg       0.99      0.99      0.99      1980\n",
            "weighted avg       0.99      0.99      0.99      1980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Linear Support Vector Classifier (SVC) को Train करें\n",
        "svc_model = LinearSVC(random_state=42)\n",
        "print(\"\\nTraining the Linear SVC Model...\")\n",
        "svc_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# 2. Prediction करें\n",
        "svc_pred = svc_model.predict(X_test_tfidf)\n",
        "\n",
        "# 3. मूल्यांकन करें\n",
        "print(\"\\n--- Linear SVC Model Evaluation Results ---\")\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test, svc_pred) * 100:.2f}%\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, svc_pred, target_names=['Fake (0)', 'Real (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArG36qSJBIsH",
        "outputId": "d4672f78-000d-493a-fce9-39cb2dedc7d9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the Linear SVC Model...\n",
            "\n",
            "--- Linear SVC Model Evaluation Results ---\n",
            "Accuracy Score: 99.75%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Fake (0)       1.00      1.00      1.00      1000\n",
            "    Real (1)       1.00      1.00      1.00       980\n",
            "\n",
            "    accuracy                           1.00      1980\n",
            "   macro avg       1.00      1.00      1.00      1980\n",
            "weighted avg       1.00      1.00      1.00      1980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the range of parameters to test\n",
        "param_grid = {'C': [0.1, 1, 10, 100]} # C is the inverse of regularization strength\n",
        "\n",
        "# Set up GridSearchCV to test parameters with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(LogisticRegression(solver='liblinear', random_state=42),\n",
        "                           param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Start training/searching\n",
        "print(\"\\nStarting Hyperparameter Tuning...\")\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# View the best parameters and score\n",
        "print(\"\\n--- Hyperparameter Tuning Results ---\")\n",
        "print(\"Best Parameters found:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model to predict on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "tuned_pred = best_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"\\nTuned Model Classification Report:\")\n",
        "print(classification_report(y_test, tuned_pred, target_names=['Fake (0)', 'Real (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVUvrjBvBhBA",
        "outputId": "e6fe048b-a6b5-427d-b822-a4f7977dab8d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Hyperparameter Tuning...\n",
            "\n",
            "--- Hyperparameter Tuning Results ---\n",
            "Best Parameters found: {'C': 100}\n",
            "Best Cross-Validation Score: 0.9964646464646464\n",
            "\n",
            "Tuned Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Fake (0)       1.00      1.00      1.00      1000\n",
            "    Real (1)       1.00      1.00      1.00       980\n",
            "\n",
            "    accuracy                           1.00      1980\n",
            "   macro avg       1.00      1.00      1.00      1980\n",
            "weighted avg       1.00      1.00      1.00      1980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'best_model' from the tuning step (or the SVC/LogisticRegression model) is your final choice.\n",
        "# We will reuse the 'preprocess_text' function and 'tfidf_vectorizer' from previous steps.\n",
        "\n",
        "# 1. Define a new article\n",
        "new_article = [\"The president announced today a major overhaul of the nation's healthcare system, receiving mixed reviews from congress.\"]\n",
        "\n",
        "# 2. Preprocess and Vectorize the new article\n",
        "# Ensure you use the SAME preprocess_text function and the SAME fitted tfidf_vectorizer\n",
        "new_article_clean = [preprocess_text(text) for text in new_article]\n",
        "new_article_vectorized = tfidf_vectorizer.transform(new_article_clean)\n",
        "\n",
        "# 3. Make the final prediction\n",
        "final_prediction = best_model.predict(new_article_vectorized) # Using the 'best_model' from tuning\n",
        "\n",
        "# 4. Display the result\n",
        "if final_prediction[0] == 1:\n",
        "    print(\"\\nPrediction: REAL News (1)\")\n",
        "else:\n",
        "    print(\"\\nPrediction: FAKE News (0)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUWhpKLeBmC4",
        "outputId": "f216bba5-3dcf-4430-c915-d7e25b92dc70"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction: REAL News (1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Assuming X_train_tfidf, X_test_tfidf, y_train, and y_test are already defined\n",
        "svc_model = LinearSVC(random_state=42)\n",
        "print(\"\\nTraining the Linear SVC Model...\")\n",
        "svc_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict and Evaluate\n",
        "svc_pred = svc_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"\\n--- Linear SVC Model Evaluation Results ---\")\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test, svc_pred) * 100:.2f}%\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, svc_pred, target_names=['Fake (0)', 'Real (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw2OVAdyBzKd",
        "outputId": "92054129-aeb6-41b5-c5b1-7972ce79c0d3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the Linear SVC Model...\n",
            "\n",
            "--- Linear SVC Model Evaluation Results ---\n",
            "Accuracy Score: 99.75%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Fake (0)       1.00      1.00      1.00      1000\n",
            "    Real (1)       1.00      1.00      1.00       980\n",
            "\n",
            "    accuracy                           1.00      1980\n",
            "   macro avg       1.00      1.00      1.00      1980\n",
            "weighted avg       1.00      1.00      1.00      1980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# We will choose the LinearSVC model since it often outperforms Logistic Regression for this type of data.\n",
        "\n",
        "# Define the model and the parameters to search\n",
        "svc_to_tune = LinearSVC(random_state=42, dual=False) # dual=False is efficient for large samples\n",
        "param_grid = {'C': [0.5, 1.0, 5.0]} # Test different regularization strengths\n",
        "\n",
        "# Set up GridSearchCV to test parameters using 3-fold cross-validation\n",
        "grid_search = GridSearchCV(svc_to_tune,\n",
        "                           param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Start training/searching on your training data\n",
        "print(\"\\nStarting Hyperparameter Tuning for Linear SVC...\")\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# --- Best Model Output ---\n",
        "print(\"\\nBest Parameters found:\", grid_search.best_params_)\n",
        "\n",
        "best_svc_model = grid_search.best_estimator_\n",
        "tuned_pred = best_svc_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"\\n--- Tuned Linear SVC Model Final Report ---\")\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test, tuned_pred) * 100:.2f}%\")\n",
        "print(classification_report(y_test, tuned_pred, target_names=['Fake (0)', 'Real (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wwiM3qPB4Aq",
        "outputId": "610d607a-f28e-4f5c-ad77-f0cbc6839fba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Hyperparameter Tuning for Linear SVC...\n",
            "\n",
            "Best Parameters found: {'C': 5.0}\n",
            "\n",
            "--- Tuned Linear SVC Model Final Report ---\n",
            "Accuracy Score: 99.75%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Fake (0)       1.00      1.00      1.00      1000\n",
            "    Real (1)       1.00      1.00      1.00       980\n",
            "\n",
            "    accuracy                           1.00      1980\n",
            "   macro avg       1.00      1.00      1.00      1980\n",
            "weighted avg       1.00      1.00      1.00      1980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reusing the 'preprocess_text' function and 'tfidf_vectorizer' from previous steps.\n",
        "\n",
        "# Define a new article to classify\n",
        "new_article = [\n",
        "    \"Exclusive: New secret talks reveal a major trade agreement is expected to be finalized next month, sources confirm.\",\n",
        "    \"Billionaire secretly funds asteroid defense shield using alien technology, claims leaked documents.\"\n",
        "]\n",
        "\n",
        "# 1. Preprocess and Vectorize the new article(s)\n",
        "new_article_clean = [preprocess_text(text) for text in new_article]\n",
        "# IMPORTANT: Use .transform(), NOT .fit_transform()\n",
        "new_article_vectorized = tfidf_vectorizer.transform(new_article_clean)\n",
        "\n",
        "# 2. Make the final prediction using your best model\n",
        "final_prediction = best_svc_model.predict(new_article_vectorized)\n",
        "\n",
        "# 3. Display the result\n",
        "print(\"\\n--- New Article Classification ---\")\n",
        "for i, pred in enumerate(final_prediction):\n",
        "    label = \"REAL News (1)\" if pred == 1 else \"FAKE News (0)\"\n",
        "    print(f\"Article {i+1} Prediction: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pSDe4ugB8wQ",
        "outputId": "347f2867-277f-404e-f8ea-527dae57f72c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Article Classification ---\n",
            "Article 1 Prediction: REAL News (1)\n",
            "Article 2 Prediction: FAKE News (0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'best_svc_model' is the best model object from your tuning step\n",
        "\n",
        "# Define some new articles (one expected to be real, one fake)\n",
        "new_articles = [\n",
        "    \"The World Health Organization confirmed an outbreak of a severe seasonal flu across several continents.\",\n",
        "    \"A secret memo reveals that squirrels are planning to seize control of the global nut supply next Tuesday.\"\n",
        "]\n",
        "\n",
        "# Reusing your existing preprocessing tools\n",
        "# ----------------------------------------------------\n",
        "# 1. Preprocess and Vectorize the new article(s)\n",
        "new_article_clean = [preprocess_text(text) for text in new_articles]\n",
        "new_article_vectorized = tfidf_vectorizer.transform(new_article_clean) # Use .transform()\n",
        "\n",
        "# 2. Make the final prediction\n",
        "final_prediction = best_svc_model.predict(new_article_vectorized)\n",
        "\n",
        "# 3. Display the result\n",
        "print(\"\\n--- Final Model Classification Test ---\")\n",
        "for i, pred in enumerate(final_prediction):\n",
        "    label = \"REAL News (1)\" if pred == 1 else \"FAKE News (0)\"\n",
        "    print(f\"Article {i+1} Prediction: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joOhkxAMCMHW",
        "outputId": "caedc451-4aa0-4991-d245-37c0fe2c1be0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Model Classification Test ---\n",
            "Article 1 Prediction: FAKE News (0)\n",
            "Article 2 Prediction: REAL News (1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount the drive (if it's already mounted, this line will be skipped)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define the save path\n",
        "save_path = '/content/drive/MyDrive/Fake_News_Model_Files/'\n",
        "\n",
        "# 3. Create the folder from the code (if it doesn't exist)\n",
        "# The os.makedirs() function creates the directory, and 'exists_ok=True' guarantees that if the folder already exists, an error will not occur.\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "print(f\"Directory created or verified at: {save_path}\")\n",
        "\n",
        "# 4. Save the model\n",
        "# Assuming 'best_svc_model' and 'tfidf_vectorizer' are defined in previous cells\n",
        "\n",
        "# save the model\n",
        "with open(save_path + 'best_svc_model.pkl', 'wb') as file:\n",
        "  pickle.dump(best_svc_model, file)\n",
        "print(\"Model saved successfully: best_svc_model.pkl\")\n",
        "\n",
        "# save the vectorizer\n",
        "with open(save_path + 'tfidf_vectorizer.pkl', 'wb') as file:\n",
        "  pickle.dump(tfidf_vectorizer, file)\n",
        "print(\"Vectorizer saved successfully: tfidf_vectorizer.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLp4I7CyFRgD",
        "outputId": "7aa0414b-d4fe-4adf-ba49-a4489648a5d1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Directory created or verified at: /content/drive/MyDrive/Fake_News_Model_Files/\n",
            "Model saved successfully: best_svc_model.pkl\n",
            "Vectorizer saved successfully: tfidf_vectorizer.pkl\n"
          ]
        }
      ]
    }
  ]
}